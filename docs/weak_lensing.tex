% Copyright David W. Hogg (NYU) and Phillip J. Marshall (Cambridge).
% All rights reserved.

\documentclass[12pt, pdftex]{article}

\newcommand{\dd}{\mathrm{d}}
\newcommand{\given}{\,|\,}
\newcommand{\RA}{\mathrm{RA}}
\newcommand{\Dec}{\mathrm{Dec}}
\newcommand{\shearpars}{\theta}
\newcommand{\position}{x}
\newcommand{\cosmopars}{\omega}
\newcommand{\densitypars}{\rho}
\newcommand{\data}{D}
\newcommand{\shape}{s}
\newcommand{\shapepars}{\alpha}

\begin{document}

\section*{white paper: How do we infer the weak-lensing shear map from an enormous amount of imaging data?}

\noindent
\textsl{[by Hogg, Marshall, others]}

\noindent
\textsl{2011-11-08}

Imagine that there is a cosmological \emph{shear map} with (an
enormous number of) parameters $\shearpars$.  This map is a
description of the weak-lensing induced distortion of galaxies as seen
by a terrestrial observer, as a function of galaxy position
$\position$.  This position $\position$ is a three-dimensional object;
you can think of it as celestial coordinates $\RA$ and $\Dec$ and
radial distance or cosmological redshift $z$.  That is, given a galaxy
position $\position$ in three-dimensional space, for any particular
setting of the parameter vector $\shearpars$, there is a definite weak
lensing shear distortion for that galaxy.

This shear map depends on three-dimensional position.  But it also
depends, in a completely different way, on the cosmological parameters
$\cosmopars$; that is, on the densities of different dynamical
components in the Universe, the Hubble constant, the amplitude of
primordial density fluctuations, and so on.  The shear-map
\emph{parameters} $\shearpars$ are themselves generated by some
physical processes, like growth of structure and cosmological
expansion, which depend on these cosmological parameters.  Another way
to put it is that, in the absence of any data (or ``prior'' to any
data), and \emph{given} a particular setting of the cosmological
parameters $\cosmopars$ it is possible (in principle and now maybe
even in practice) to write down a probability distribution function
over shear map parameters $\shearpars$; we will denote this
\begin{eqnarray}\displaystyle
p(\shearpars\given\cosmopars)
\quad ,
\end{eqnarray}
which is a \emph{probability distribution function} (PDF) over the
enormous shear-map parameter vector $\shearpars$ given the
cosmological parameters $\cosmopars$.

In detail, this probability distribution function is most likely to be
computed via a three-dimensional map of the mass density; that is, it
might be better to think of this as looking something like
\begin{eqnarray}\displaystyle
p(\shearpars\given\cosmopars) &=& \int p(\shearpars\given\densitypars)\,p(\densitypars\given\cosmopars)\,\dd\densitypars
\quad ,
\end{eqnarray}
where the density-map parameters are in an enormous vector
$\densitypars$.  This point is only meant to clarify the relationship
between the shear-map parameters and the cosmological parameters: The
cosmological parameters create structure, and structure lenses
observed sources.  From now on, we will ignore the density map; we
will assume that it can be (effectively) integrated out; we will
imagine that we can write down---or really calculate with massive
computational facilities---the PDF $p(\shearpars\given\cosmopars)$.

Now let's think about a single galaxy $n$.  We have taken some useful
data $\data_n$ on galaxy $n$, where the vector $\data_n$ might include
celestial coordinates, photometric information, redshift information,
and high-resolution imaging.  Although all these data are noisy,
including even the position and redshift information, we can imagine
that each galaxy has a definite (but only imprecisely known) position
$\position_n$.  The imaging data are also noisy, but again we can
imagine that each galaxy has a definite true \emph{shape} $\shape_n$,
which we can think of as being the shape we ``would have observed'' in
the absence of any weak-lensing distortion.  This shape $\shape_n$ can
be thought of also as a big parameter vector, perhaps the amplitudes
of ``shapelet'' components or of pixel values in a small,
high-resolution pixellated image.  Or it could even be a
three-dimensional model plus Euler angles.  The investigator has huge
freedom in the parameterization of galaxy shape (as with the shear map
and even the cosmological parameters).

As with the shear map, we are going to reason probabilistically, in
the following sense: Galaxies do not have fully arbitrary shapes
$\shape$; the shapes are drawn from some very compact and informative
PDF $p(\shape\given\shapepars,\position)$, parameterized by some (again
very large) vector of parameters $\shapepars$ and position $\position$
(because of galaxy evolution; it depends on redshift).  It is clear
that there \emph{is} such a parameterization, because we all know a
galaxy when we see it, but here's the rub: After more than a century
of quantitative investigation of galaxies, \emph{we have no
  community-accepted description of the PDF for galaxy shapes}, let
alone as a function of redshift!

Weak lensing is not the only field that needs this PDF.  As we have
argued elsewhere, you need this to find strong gravitational lenses in
a justified automated way.  You need this to create a
probabilistically responsible system for ``deblending'' images of
overlapping or merging galaxies.  You need this to convert
observations of galaxies over cosmic time into a quantitative
description of morphological evolution.  You need this, also, if
galaxy morphology is ever to become part of any precise scientific
activity.

Now let's imagine that a miracle happens and we are handed a
parameterized PDF for galaxy shapes $p(\shape\given\shapepars)$ with
parameter vector $\shapepars$.  This PDF, plus a PSF and noise model
for our imaging, will permit information-limited measurements of the
shear map.  We start with a likelihood function
\begin{eqnarray}\displaystyle
p(\data_n\given\shape_n,\position_n,\shearpars)
\quad ,
\end{eqnarray}
which provides the probability we get some particular data $\data_n$
given the true shape $\shape_n$ and the shear (which is given by the
shear map $\shearpars$ and the position $\position_n$).  This PDF
involves the PSF because the shear-distorted true shape has been
convolved with the PSF before observation, and it involves the noise
model, because the finite exposure time and the detector properties
make any data $\data_n$ a noisy representation of the PSF-convolved
shape.

If we are cosmologists---that is, if all we care about are
cosmological matters---then the true shape $\shape_n$ and true
position $\position_n$ of galaxy $n$ are of no interest---nor are the
parameters of the shape distribution $\shapepars$---they are
nuisances.  Let's integrate them out with
\begin{eqnarray}\displaystyle
p(\data_n\given\position_n,\shearpars,\shapepars) &=&
\int p(\data_n\given\shape_n,\position_n,\shearpars)\,p(\shape_n\given\shapepars,\position_n)\,\dd\shape_n
\\
p(\data_n\given\shearpars,\shapepars) &=&
\int p(\data_n\given\position_n,\shearpars,\shapepars)\,p(\position_n)\,\dd\position_n
\\
p(\data\given\shearpars) &=&
\int \left[\prod_n p(\data_n\given\shearpars,\shapepars)\right]\,p(\shapepars)\,\dd\shapepars
\quad ,
\end{eqnarray}
where the two integrals take care of the nuisances, we denote the full
data set (the data $\data_n$ for all $n$) by $\data$, and we have
assumed that the shape distribution depends on redshift (via the
position $\position_n$, the independently drawn galaxy likelihoods can
be multiplied together but share the same shape distribution, and that
the prior PDFs over positions $p(\position)$ and shape distribution
parameters $p(\shapepars)$ are both trivial (require no parameters),
either because (in the case of position) they are known well from
other studies of galaxies or else (in the case of shape distribution
parameters) we are willing to make uninformative or default choices.
All this can be generalized, of course.  These integrals are enormous
and will have to be performed with clever sampling or approximate
methods, we suspect.  It is worthy of note in these marginalizations
the role of the prior PDFs as measures for integration.  Priors are
necessary if we want to get rid of nuisance parameters.

Continuing on to cosmological parameters, the shear map \emph{itself}
can be thought of as another huge set of nuisance parameters in the
following sense:
\begin{eqnarray}\displaystyle
p(\data\given\cosmopars) &=&
\int p(\data\given\shearpars)\,p(\shearpars\given\cosmopars)\,\dd\shearpars
\quad.
\end{eqnarray}
This is the likelihood that we (ought to) seek: The probability of the
data $\data$ (meaning all the data on all galaxies $n$ combined) as a
function of cosmological parameters $\cosmopars$.  This is the analog
of the likelihood function exposed or published by the \textsl{WMAP}
collaboration but for shear data rather than microwave background
data.

The \textsl{WMAP} likelihood function did not involve a terrible
explicit marginalization because the cosmic microwave background map
is related to the cosmological parameters so simply.  But it
\emph{did} involve a large \emph{implicit} marginalization over the
\emph{phases} of the map (because the cosmological parameters predict
only the amplitudes of the modes).  In the case of weak lensing, there
is no way to hide or implicitly marginalize, because the cosmological
parameters interact with the map and the map interacts with the data
with so many nonlinearities and complications.

\end{document}
